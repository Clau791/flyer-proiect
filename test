from __future__ import annotations

import logging
import os
import threading
import time
from pathlib import Path
from typing import List, Tuple, Dict
import requests

import ffmpeg
import pysubs2
import whisper
from deep_translator import GoogleTranslator

from services.progress_bar import send_task_progress
from services.category_v.summary_service import SummaryService


class SubtitleGenerator:
    """
    Flux complet de subtitrare:
    1) Transcriere video cu Whisper (auto detectează limba).
    2) Traducere via Local High-End Server (RTX 5090) cu fallback la Cloud.
    3) Scriere SRT în 'processed/'.
    4) Dacă attach_mode == 'hard', arde subtitrarea în video cu ffmpeg.
    """

    def __init__(
        self,
        processed_dir: str = "processed",
        whisper_model: str = "small",
    ):
        self.processed_dir = Path(processed_dir)
        self.processed_dir.mkdir(parents=True, exist_ok=True)
        self.whisper_model_name = whisper_model
        self._model = None
        self._global_start = None
        self._total_expected = None
        self._summary_service = SummaryService()
        
        # Configurare Server Local Traducere
        self._local_server_url = os.getenv("LOCAL_TRANSLATION_URL", "http://localhost:8001/translate")
        self._session = requests.Session() # Conexiune persistentă pentru viteză

        # Configurare Legacy (Ollama / Fallback)
        self._ollama_host = os.getenv("OLLAMA_HOST", "http://127.0.0.1:11434")
        self._ollama_models = [
            os.getenv("OLLAMA_MODEL_PRIMARY", "llama3:70b"),
            os.getenv("OLLAMA_MODEL_FALLBACK", "qwen:14b"),
        ]

        # Mapare simplă pentru coduri Whisper -> Nume complete (preferate de ALMA/Qwen)
        self._lang_map = {
            "ro": "Romanian", "en": "English", "fr": "French", 
            "de": "German", "it": "Italian", "es": "Spanish",
            "ru": "Russian", "zh": "Chinese", "ja": "Japanese",
            "pt": "Portuguese"
        }

    # ------------ Internals ------------
    def _load_model(self):
        if self._model is None:
            # Lazy loading pentru a evita costul la import
            self._model = whisper.load_model(self.whisper_model_name)
        return self._model

    def _map_lang_code(self, code: str) -> str:
        """Convertește 'en' -> 'English' pentru prompt-ul modelului LLM."""
        return self._lang_map.get(code.lower(), code.title())

    def _transcribe(self, filepath: str):
        model = self._load_model()
        # verbose=False reduce zgomotul în consolă
        result = model.transcribe(filepath, task="transcribe", verbose=False)
        segments = result.get("segments", [])
        language = result.get("language", "auto")
        return segments, language

    def _translate_via_server(self, text: str, source_code: str, target_code: str) -> str:
        """
        Trimite cerere către serverul local Python (FastAPI) de pe portul 8001.
        """
        source_lang = self._map_lang_code(source_code)
        target_lang = self._map_lang_code(target_code)
        
        payload = {
            "text": text,
            "source_lang": source_lang,
            "target_lang": target_lang,
            "temperature": 0.1 # Temperatură mică pentru fidelitate maximă
        }

        try:
            resp = self._session.post(self._local_server_url, json=payload, timeout=30)
            if resp.status_code == 200:
                data = resp.json()
                return data.get("translation", "").strip()
            else:
                logging.warning(f"[SUBTITLE] Server Error {resp.status_code}: {resp.text}")
                return ""
        except requests.exceptions.ConnectionError:
            logging.error(f"[SUBTITLE] Nu mă pot conecta la serverul local: {self._local_server_url}")
            return "CONNECTION_ERROR"
        except Exception as e:
            logging.warning(f"[SUBTITLE] Eroare traducere server: {e}")
            return ""

    def _translate_ollama(self, text: str, target_lang: str) -> str:
        """Fallback method pentru Ollama standard."""
        try:
            system_prompt = (
                f"Ești un traducător profesionist. Tradu textul EXACT în limba {target_lang}. "
                f"Păstrează sensul, numele proprii și ordinea logică. "
                f"Output-ul trebuie să conțină DOAR traducerea."
            )
            user_prompt = f"Text: {text}\nTraducere:"
            
            for mdl in self._ollama_models:
                try:
                    resp = requests.post(
                        f"{self._ollama_host}/v1/completions",
                        json={
                            "model": mdl,
                            "prompt": f"{system_prompt}\n\n{user_prompt}",
                            "options": {"temperature": 0.1},
                        },
                        timeout=60,
                    )
                    if resp.ok:
                        data = resp.json()
                        txt = (data.get("choices") or [{}])[0].get("text", "").strip()
                        if txt: return txt
                except:
                    continue
        except Exception as e:
            logging.warning(f"[SUBTITLE] Ollama fallback failed: {e}")
        return ""

    def _translate_segments(
        self, 
        segments: List[dict], 
        source_lang_detected: str, 
        target_lang: str, 
        mode: str = "local_server"
    ) -> Tuple[List[str], List[str]]:
        """
        Returnează (texte_traduse, texte_originale).
        """
        translated, originals = [], []
        
        # Inițializăm Cloud Translator doar dacă e cerut explicit sau ca fallback
        cloud_translator = None
        if mode == "cloud":
            cloud_translator = GoogleTranslator(source="auto", target=target_lang)

        server_available = True

        for i, seg in enumerate(segments):
            orig = (seg.get("text") or "").strip()
            originals.append(orig)
            
            if not orig:
                translated.append("")
                continue

            # Logica de selecție a metodei
            translation = ""

            # 1. Încercăm Serverul Local High-End (Prioritate)
            if mode == "local_server" and server_available:
                translation = self._translate_via_server(orig, source_lang_detected, target_lang)
                
                if translation == "CONNECTION_ERROR":
                    logging.warning("[SUBTITLE] Serverul local nu răspunde. Trecem pe fallback (Cloud/Ollama).")
                    server_available = False # Dezactivăm serverul pentru restul segmentelor
                    translation = "" # Forțăm intrarea în fallback
                elif not translation:
                     # Serverul a răspuns dar gol sau eroare internă
                     pass

            # 2. Fallback: Google Translate (dacă serverul a picat sau mode="cloud")
            if not translation:
                try:
                    if not cloud_translator:
                        cloud_translator = GoogleTranslator(source="auto", target=target_lang)
                    translation = cloud_translator.translate(orig)
                except Exception as e:
                    logging.debug(f"Google translate fail: {e}")

            # 3. Fallback Ultim: Ollama vechi (dacă există)
            if not translation:
                translation = self._translate_ollama(orig, target_lang)

            # 4. Fail-safe
            translated.append(translation if translation else orig)

            # Log progress discret (la fiecare 10 segmente)
            if i % 10 == 0:
                logging.info(f"[SUBTITLE] Tradus segment {i}/{len(segments)}")

        return translated, originals

    def _write_srt(self, segments: List[dict], texts: List[str], srt_path: Path):
        subs = pysubs2.SSAFile()
        for seg, txt in zip(segments, texts):
            start_ms = int(float(seg.get("start", 0)) * 1000)
            end_ms = int(float(seg.get("end", 0)) * 1000)
            event = pysubs2.SSAEvent(start=start_ms, end=end_ms, text=txt)
            subs.append(event)
        subs.save(str(srt_path), encoding="utf-8")

    def _burn_subtitles(self, video_path: Path, srt_path: Path, output_path: Path):
        srt_escaped = srt_path.as_posix().replace("'", r"\\'")
        (
            ffmpeg
            .input(str(video_path))
            .output(
                str(output_path),
                vf=f"subtitles='{srt_escaped}'",
                acodec="copy",
                vcodec="libx264",
                preset="fast",
                crf=18,
            )
            .overwrite_output()
            .run(quiet=True)
        )

    def _probe_duration(self, video_path: Path) -> float:
        try:
            meta = ffmpeg.probe(str(video_path))
            for stream in meta.get("streams", []):
                if stream.get("codec_type") == "video" and stream.get("duration"):
                    return float(stream["duration"])
            if "format" in meta and meta["format"].get("duration"):
                return float(meta["format"]["duration"])
        except Exception:
            return 0.0
        return 0.0

    def _estimate_timeline(self, duration: float, attach_mode: str):
        rt_factor = 1.2
        translate_factor = 0.3 # Puțin mai mult pentru inferență locală de calitate
        burn_factor = 0.5
        summary_factor = 0.15

        duration = max(duration, 60.0)
        est_transcribe = duration * rt_factor
        est_translate = duration * translate_factor
        est_burn = duration * burn_factor if attach_mode == "hard" else 0.0
        est_summary = duration * summary_factor
        
        return {
            "transcribe": est_transcribe,
            "translate": est_translate,
            "burn": est_burn,
            "summary": est_summary,
            "total": est_transcribe + est_translate + est_burn + est_summary + 10.0,
        }

    def _run_stage(self, label: str, expected_seconds: float, base_percent: float, weight_percent: float, func):
        start = time.time()
        done = threading.Event()

        def ticker():
            while not done.is_set():
                elapsed = time.time() - start
                ratio = min(1.0, elapsed / max(expected_seconds, 0.1))
                percent = base_percent + ratio * weight_percent
                eta = max(0.0, (self._total_expected or expected_seconds) - (time.time() - self._global_start))
                send_task_progress(percent=percent, eta_seconds=eta, stage=label, detail="în curs")
                time.sleep(1.0)

        t = threading.Thread(target=ticker, daemon=True)
        t.start()
        try:
            result = func()
        finally:
            done.set()
            t.join(timeout=0.2)

        percent = base_percent + weight_percent
        eta = max(0.0, (self._total_expected or expected_seconds) - (time.time() - self._global_start))
        send_task_progress(percent=percent, eta_seconds=eta, stage=label, detail="finalizat")
        return result

    # ------------ API publică ------------
    def generate(self, filepath: str, lang: str = "ro", attach_mode: str = "soft", detail_level: str = "medium", translator_mode: str = "local_server"):
        """
        Generează subtitrare.
        
        Args:
            translator_mode: 'local_server' (Recomandat - RTX 5090), 'cloud' (Google), 'ollama'.
        """
        video_path = Path(filepath)
        attach_mode = (attach_mode or "soft").lower()
        translator_mode = (translator_mode or "local_server").lower()
        
        print(f"[SUBTITLE] Start: Mode={attach_mode}, Translator={translator_mode}")
        self._global_start = time.time()

        duration = self._probe_duration(video_path)
        timeline = self._estimate_timeline(duration, attach_mode)
        self._total_expected = timeline["total"]

        # Ponderi progres
        pct_transcribe = 50.0
        pct_translate = 30.0 # Creștem ponderea traducerii fiind neurală
        pct_summary = 10.0
        pct_burn = 0.0 if attach_mode != "hard" else 10.0
        
        send_task_progress(percent=1.0, eta_seconds=timeline["total"], stage="init", detail="pregătire")

        # 1. Transcriere
        segments, detected_lang = self._run_stage(
            "transcriere",
            timeline["transcribe"], 0.0, pct_transcribe,
            lambda: self._transcribe(str(video_path)),
        )
        print(f"[SUBTITLE] Limbă detectată: {detected_lang}")

        # 2. Traducere (Aici e magia nouă)
        print(f"[SUBTITLE] Începe traducerea cu {translator_mode}...")
        translated_texts, originals = self._run_stage(
            "traducere",
            timeline["translate"], pct_transcribe, pct_translate,
            lambda: self._translate_segments(
                segments, 
                source_lang_detected=detected_lang, 
                target_lang=lang, 
                mode=translator_mode
            ),
        )

        # 3. Scriere SRT
        srt_path = self.processed_dir / f"{video_path.stem}_{lang}.srt"
        self._write_srt(segments, translated_texts, srt_path)

        # 4. Rezumat
        full_text = "\n".join(translated_texts)
        summary_result = self._run_stage(
            "rezumat",
            timeline["summary"], pct_transcribe + pct_translate, pct_summary,
            lambda: self._summary_service.summarize_content(
                content_id=video_path.stem,
                text=full_text,
                metadata={"source": "video", "lang": lang, "detail": detail_level},
            ),
        )

        response = {
            "attach_mode": attach_mode,
            "subtitle_file": f"/download/{srt_path.name}",
            "subtitle_language": lang,
            "detected_language": detected_lang,
            "segments": len(segments),
            "summary": summary_result.get("summary"),
        }

        # 5. Hard Burn (Opțional)
        if attach_mode == "hard":
            output_video = self.processed_dir / f"{video_path.stem}_{lang}_subtitled.mp4"
            self._run_stage(
                "burn",
                timeline["burn"], pct_transcribe + pct_translate + pct_summary, pct_burn,
                lambda: self._burn_subtitles(video_path, srt_path, output_video),
            )
            response["video_file"] = f"/download/{output_video.name}"
        else:
            response["video_file"] = f"/download/{srt_path.name}"

        send_task_progress(percent=100.0, eta_seconds=0.0, stage="gata", detail="complet")
        return response
